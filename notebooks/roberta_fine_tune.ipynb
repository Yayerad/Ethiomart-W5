{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch\n",
    "!pip install seqeval  # for evaluating NER performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CoNLL format dataset\n",
    "data = pd.read_csv('path_to_your_conll_dataset.txt', delimiter='\\t', header=None)\n",
    "# Example: ['Token', 'Label'] format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizer\n",
    "\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples['text'], padding=True, truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = examples['labels']\n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Assuming you have a 'text' and 'labels' column in your dataset\n",
    "tokenized_dataset = data.map(tokenize_and_align_labels, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Define Training Arguments:\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory for the model\n",
    "    evaluation_strategy=\"epoch\",     # evaluate after each epoch\n",
    "    learning_rate=2e-5,              # learning rate\n",
    "    per_device_train_batch_size=16,  # batch size for training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    num_train_epochs=3,              # number of training epochs\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Initialize the Model:\n",
    "from transformers import XLMRobertaForTokenClassification\n",
    "\n",
    "model = XLMRobertaForTokenClassification.from_pretrained('xlm-roberta-base', num_labels=len(label_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Set Up the Trainer:\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the model to be fine-tuned\n",
    "    args=training_args,                  # training arguments\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=eval_dataset,           # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # evaluation metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    true_labels = labels\n",
    "\n",
    "    results = []\n",
    "    for pred, true in zip(predictions, true_labels):\n",
    "        temp_pred, temp_true = [], []\n",
    "        for p, t in zip(pred, true):\n",
    "            if t != -100:  # Skip padding tokens\n",
    "                temp_pred.append(p)\n",
    "                temp_true.append(t)\n",
    "        results.append((temp_pred, temp_true))\n",
    "\n",
    "    precision = precision_score(results)\n",
    "    recall = recall_score(results)\n",
    "    f1 = f1_score(results)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save the Fine-Tuned Model\n",
    "model.save_pretrained('fine_tuned_model')\n",
    "tokenizer.save_pretrained('fine_tuned_model')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
